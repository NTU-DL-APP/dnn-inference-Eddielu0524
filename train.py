import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
import json

# è¨­ç½®éš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿çµæœå¯é‡ç¾
np.random.seed(42)
tf.random.set_seed(42)

# æ¨¡å‹æ–‡ä»¶è·¯å¾‘
YOUR_MODEL_NAME = 'fashion_mnist'
TF_MODEL_PATH = f'{YOUR_MODEL_NAME}.h5'
MODEL_WEIGHTS_PATH = f'{YOUR_MODEL_NAME}.npz'
MODEL_ARCH_PATH = f'{YOUR_MODEL_NAME}.json'

def create_optimized_model():
    """å‰µå»ºå„ªåŒ–çš„ Fashion-MNIST åˆ†é¡æ¨¡å‹"""
    model = keras.Sequential([
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(512, activation='relu', name='dense_1'),
        keras.layers.BatchNormalization(name='batch_norm_1'),
        keras.layers.Dropout(0.3, name='dropout_1'),
        keras.layers.Dense(256, activation='relu', name='dense_2'),
        keras.layers.BatchNormalization(name='batch_norm_2'),
        keras.layers.Dropout(0.3, name='dropout_2'),
        keras.layers.Dense(128, activation='relu', name='dense_3'),
        keras.layers.Dropout(0.2, name='dropout_3'),
        keras.layers.Dense(10, activation='softmax', name='output')
    ])

    return model

def train_model():
    """è¨“ç·´ Fashion-MNIST æ¨¡å‹"""
    print("ğŸš€ é–‹å§‹è¨“ç·´ Fashion-MNIST æ¨¡å‹...")

    # è¼‰å…¥æ•¸æ“š
    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()

    # é è™•ç†
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    y_train = keras.utils.to_categorical(y_train, 10)
    y_test = keras.utils.to_categorical(y_test, 10)

    print(f"è¨“ç·´é›†å½¢ç‹€: {x_train.shape}")
    print(f"æ¸¬è©¦é›†å½¢ç‹€: {x_test.shape}")

    # å‰µå»ºæ¨¡å‹
    model = create_optimized_model()

    # ç·¨è­¯æ¨¡å‹
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # è¨­ç½®å›èª¿
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=15,
            restore_best_weights=True,
            verbose=1
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7,
            verbose=1
        )
    ]

    # è¨“ç·´
    history = model.fit(
        x_train, y_train,
        batch_size=128,
        epochs=100,
        validation_data=(x_test, y_test),
        callbacks=callbacks,
        verbose=1
    )

    # è©•ä¼°
    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
    print(f"\\nğŸ“Š æœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {test_accuracy:.4f}")

    # ä¿å­˜æ¨¡å‹
    model.save(TF_MODEL_PATH)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {TF_MODEL_PATH}")

    return model, test_accuracy

def convert_model_to_numpy(model):
    """å°‡ TensorFlow æ¨¡å‹è½‰æ›ç‚º NumPy æ ¼å¼"""
    print("\\nğŸ”„ è½‰æ›æ¨¡å‹æ ¼å¼...")

    # === æå–æ¬Šé‡ ===
    params = {}
    print("ğŸ” æå–æ¬Šé‡...")

    for layer in model.layers:
        weights = layer.get_weights()
        if weights:
            print(f"  è™•ç†å±¤: {layer.name}")
            for i, w in enumerate(weights):
                param_name = f"{layer.name}_{i}"
                print(f"    {param_name}: shape={w.shape}")
                params[param_name] = w

    # ä¿å­˜æ¬Šé‡
    np.savez(MODEL_WEIGHTS_PATH, **params)
    print(f"âœ… æ¬Šé‡å·²ä¿å­˜: {MODEL_WEIGHTS_PATH}")

    # === æå–æ¶æ§‹ ===
    arch = []
    print("\\nğŸ—ï¸  æå–æ¶æ§‹...")

    for layer in model.layers:
        config = layer.get_config()
        info = {
            "name": layer.name,
            "type": layer.__class__.__name__,
            "config": config,
            "weights": [f"{layer.name}_{i}" for i in range(len(layer.get_weights()))]
        }
        arch.append(info)
        print(f"  æ·»åŠ å±¤: {layer.name} ({layer.__class__.__name__})")

    # ä¿å­˜æ¶æ§‹
    with open(MODEL_ARCH_PATH, "w") as f:
        json.dump(arch, f, indent=2)
    print(f"âœ… æ¶æ§‹å·²ä¿å­˜: {MODEL_ARCH_PATH}")

def test_numpy_inference():
    """æ¸¬è©¦ NumPy æ¨ç†åŠŸèƒ½"""
    print("\\nğŸ§ª æ¸¬è©¦ NumPy æ¨ç†...")

    # è¼‰å…¥æ¬Šé‡å’Œæ¶æ§‹
    weights = np.load(MODEL_WEIGHTS_PATH)
    with open(MODEL_ARCH_PATH) as f:
        architecture = json.load(f)

    print(f"è¼‰å…¥æ¬Šé‡æ–‡ä»¶: {len(weights.files)} å€‹åƒæ•¸")
    print(f"è¼‰å…¥æ¶æ§‹æ–‡ä»¶: {len(architecture)} å±¤")

    # æ¿€æ´»å‡½æ•¸
    def relu(x):
        return np.maximum(0, x)

    def softmax(x):
        e = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return e / np.sum(e, axis=-1, keepdims=True)

    def flatten(x):
        return x.reshape(x.shape[0], -1)

    def dense(x, W, b):
        return x @ W + b

    # å‰å‘å‚³æ’­
    def forward(x):
        for layer in architecture:
            lname = layer['name']
            ltype = layer['type']
            cfg = layer['config']
            wnames = layer['weights']

            if ltype == "Flatten":
                x = flatten(x)
                print(f"  {lname}: {ltype} -> shape: {x.shape}")

            elif ltype == "Dense":
                if len(wnames) >= 2:
                    W = weights[wnames[0]]
                    b = weights[wnames[1]]
                    x = dense(x, W, b)

                    # æ‡‰ç”¨æ¿€æ´»å‡½æ•¸
                    activation = cfg.get("activation", "linear")
                    if activation == "relu":
                        x = relu(x)
                    elif activation == "softmax":
                        x = softmax(x)

                    print(f"  {lname}: {ltype}({activation}) -> shape: {x.shape}")

            elif ltype in ["BatchNormalization", "Dropout"]:
                # æ¨ç†æ™‚è·³éé€™äº›å±¤
                print(f"  {lname}: {ltype} (è·³é)")
                continue

        return x

    # æ¸¬è©¦æ¨ç†
    print("\\nğŸ¯ åŸ·è¡Œæ¸¬è©¦æ¨ç†...")
    dummy_input = np.random.rand(1, 28, 28).astype(np.float32)
    output = forward(dummy_input)

    print(f"\\nğŸ“Š è¼¸å‡ºæ¦‚ç‡: {output[0]}")
    print(f"ğŸ¯ é æ¸¬é¡åˆ¥: {np.argmax(output, axis=-1)[0]}")
    print(f"ğŸ”¢ æœ€é«˜æ¦‚ç‡: {np.max(output):.4f}")

    return True

def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 50)
    print("ğŸ¯ Fashion-MNIST å®Œæ•´è§£æ±ºæ–¹æ¡ˆ")
    print("=" * 50)

    try:
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰è¨“ç·´å¥½çš„æ¨¡å‹
        if os.path.exists(TF_MODEL_PATH):
            print(f"ğŸ“ ç™¼ç¾ç¾æœ‰æ¨¡å‹: {TF_MODEL_PATH}")
            model = keras.models.load_model(TF_MODEL_PATH)

            # å¿«é€Ÿè©•ä¼°
            (_, _), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
            x_test = x_test.astype('float32') / 255.0
            y_test = keras.utils.to_categorical(y_test, 10)
            _, accuracy = model.evaluate(x_test, y_test, verbose=0)
            print(f"ğŸ“Š ç¾æœ‰æ¨¡å‹æº–ç¢ºç‡: {accuracy:.4f}")

        else:
            # è¨“ç·´æ–°æ¨¡å‹
            model, accuracy = train_model()

        # è½‰æ›æ¨¡å‹æ ¼å¼
        convert_model_to_numpy(model)

        # æ¸¬è©¦ NumPy æ¨ç†
        test_numpy_inference()

        print("\\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰ä»»å‹™å®Œæˆï¼")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  - {TF_MODEL_PATH} (TensorFlow æ¨¡å‹)")
        print(f"  - {MODEL_WEIGHTS_PATH} (NumPy æ¬Šé‡)")
        print(f"  - {MODEL_ARCH_PATH} (JSON æ¶æ§‹)")
        print("=" * 50)

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
